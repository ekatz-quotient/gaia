<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>GAIA</title>
        <meta http-equiv="Content-Type" content="text/html;"/>
        <meta charset="utf-8"/>
        <link rel='stylesheet' type='text/css' href="https://fonts.googleapis.com/css?family=Ubuntu:400,700,400italic"/>
        <link rel="stylesheet" type="text/css" href="doxygen.css" title="default" media="screen,print" />
        <script type="text/javascript" src="jquery.js"></script>
        <script type="text/javascript" src="https://rawcdn.githack.com/doxygen/doxygen/5213707f485360bd9145beebe2fab250ca133a02/templates/html/dynsections.js"></script>
    </head>
    <body>
        <div id="banner-container">
            <div id="banner">
                <span id="gaia">GAIA 0.1.0</span>
            </div>
        </div>
        <div id="content">
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">GSOD weather - tutorial </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a href="https://github.com/romange/gaia/blob/master/examples/gsod_group.cc">gsod_group.cc</a> file demonstrates a map/reshard/group pattern that often is needed when processing large datasets. The framework provides just partitioning (resharding), while joining (or grouping) is done in the user code. This way, unlike in <code>Beam</code> or similar frameworks, the developer has more control on how to reduce unnecesary I/O.</p>
<h3>Preliminaries</h3>
<p>The first example we will cover is processing of <a href="https://console.cloud.google.com/bigquery?p=bigquery-public-data&amp;d=samples&amp;t=gsod&amp;page=table">GSOD weather dataset</a> from <a href="https://cloud.google.com/bigquery/public-data/">Google Bigquery Public Datasets</a>.</p>
<p>In order to read its data we need to export this table to GCS first. I've prepared publicly accessible sampled dataset at <code>gs://kushkush/gsod/</code> that you can copy to you local disk or access it directly from mr3. For latter, I suggest you to run the pipeline from cloud instance in order to allow maximum performance. You will also need gcloud sdk installed with <code>~/.config/gcloud/</code> directory if you access GCS files directly from mr3.</p>
<h3>Reading inputs</h3>
<p>At first, we instruct the pipeline to read text files and skip the first line in each file. The input files could be compressed or uncompressed - that's transparent to user and is auto-detected upon read. Both gzip and zstd compressions are supported. Text files are treated as bag of lines and the pipeline will process those lines independently from each other. In general any mr3 stream is represented as unordered, possibly sharded list of records using C++ handle <code>PTable&lt;MyRecordType&gt;</code>. In this case it's just unsharded <code>PTable&lt;string&gt;</code>. In addition, the input files could be read from the local disk or from gcs storage. For example, </p><div class="fragment"><div class="line">./gsod_group gs://kushkush/gsod/gsod-shards-0*</div></div><!-- fragment --><p>or </p><div class="fragment"><div class="line">./gsod_group &#39;/tmp/gsod/gsod-shards-0*&#39;</div></div><!-- fragment --><p> are both valid invocations. The framework will expand GCS prefix or a bash glob accordingly. Note, that the framework currently supports GCS globs with '*' at the end, or '**' for the recursive glob.</p>
<p>Then we instruct our pipeline to run our mapper to parse each line into a meaningful record. In this case our files are in CSV format and we decided that we extract the columns we need into <code>GsodRecord</code>. In particular we keep only a <code>year</code> and <code>station</code> columns.</p>
<p>To make our own C++ class <code>GsodRecord</code> serializable within <code>mr3</code> we must specialize <code>template &lt;&gt; class <a class="el" href="structmr3_1_1RecordTraits.html">mr3::RecordTraits</a>&lt;GsodRecord&gt;</code> with 2 methods <code>Serialize</code> and <code>Parse</code>. They will be used later when our mapper outputs the extracted records using <code>DoContext&lt;GsodRecord&gt;</code>.</p>
<p>Our mapper is expected to have a hook method <code>void Do(InputType val, <a class="el" href="classmr3_1_1DoContext.html">mr3::DoContext</a>&lt;OutputType&gt;* context)</code>. In our case <code>InputType</code> is <code>std::string</code> since we process string table and <code>OutputType</code> is <code>GsodRecord</code>. Please note that the framework determines based on the signature of <code>GsodMapper::Do</code> the type of the result table <code>PTable&lt;GsodRecord&gt;</code>.</p>
<p>The mapper can output as many records as it wishes upon each input record it processes or not output at all. This allows to filter, expand or do other transformations on the data.</p>
<p>In addition, a mapper can have <code>void OnShardFinish(DoContext&lt;OutputType&gt;* context);</code> hook that will be called when the mapper has finished processing a batch of records scheduled by the framework. Anyway, in this case <code>GsodMapper</code> just outputs a single <code>GsodRecord</code> record per input line.</p>
<div class="fragment"><div class="line">StringTable ss = pipeline-&gt;ReadText(<span class="stringliteral">&quot;gsod&quot;</span>, inputs).set_skip_header(1);</div><div class="line">PTable&lt;GsodRecord&gt; records = ss.Map&lt;GsodMapper&gt;(<span class="stringliteral">&quot;MapToGsod&quot;</span>);</div></div><!-- fragment --><h3>Resharding</h3>
<p>In order to cope with large amounts of data that can not be hold in RAM, our framework allows to repartition or as we call it 're-shard' the data before applying next the operator.</p>
<div class="fragment"><div class="line">records.Write(<span class="stringliteral">&quot;gsod_map&quot;</span>, pb::WireFormat::TXT)</div><div class="line">      .WithModNSharding(10, [](<span class="keyword">const</span> GsodRecord&amp; r) { <span class="keywordflow">return</span> r.year; })</div><div class="line">      .AndCompress(pb::Output::GZIP);</div></div><!-- fragment --><p>This line instructs the framework to reshard the mapped table of GsodRecords by year into 10 shards. The final shards will also be compressed. Resharding is crucial to bring records of particular property together so that we could load them into RAM. Since we used ModN sharding it most likely that each file shard will contain multiple years of data but every unique year will be hold by exactly one file shard. The developer is expected to choose shards count in such way that the input data divided by number of shards will be less than <code>total RAM available</code> / <code>number of cores on the machine</code>. The number of shards is bounded from above by file limit of the system ( it's usually less than 10K though it's customizable). Producing only few shards is also not very good, because it might affect the level of parallelism when running the next operator.</p>
<h3>GroupBy</h3>
<p>Finally we apply the operator that processed each shard assuming that entities of the same year are located together. Please note that unlike with other frameworks the operator does not get any guarantees on the order of the entities inside shard and must handle them by its own. Low guarantees put more reponsibility on a developer but provide more performant framework with less I/O.</p>
<p><code>Join</code> operator can read multiple sharded inputs, in case we want to join multiple sources of data. In order to bind each input with its own handler function we have <code>records.BindWith(&amp;GsodJoiner::Group)</code> call that tell the framework that in this case we want that <code>records</code> table will be handled by <code>GsodJoiner::Group</code> handler. In our case we have only one input that we want to process by counting all the records per year.</p>
<p>As we said earlier, each shard might span multiple years of data so we use absl hash table to count number of records per year. After a shard is processed, the framework calls <code>void GsodJoiner::OnShardFinish</code> where our operator outputs the counts per year it processed.</p>
<div class="fragment"><div class="line">StringTable joined =</div><div class="line">      pipeline-&gt;Join&lt;GsodJoiner&gt;(<span class="stringliteral">&quot;group_by&quot;</span>, {records.BindWith(&amp;GsodJoiner::Group)});</div></div><!-- fragment --><h3>Running the pipeline</h3>
<p>All the commands above only configure the framework with user-provided operators and bind them with the appropriate inputs. The entry point that triggers the run is the call <code>pipeline-&gt;Run(runner);</code>. The framework comes with already implemented <code>Runner</code> that provides fiber friendly, multi-threaded single machine processing. This <code>LocalRunner</code> requires a destination directory to store its intermediate and final outputs. Once the run is completed the process finishes.</p>
<div class="fragment"><div class="line">LocalRunner* runner = pm.StartLocalRunner(FLAGS_dest_dir);</div><div class="line">pipeline-&gt;Run(runner);</div></div><!-- fragment --> </div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.15
</small></address>
</body>
</html>
